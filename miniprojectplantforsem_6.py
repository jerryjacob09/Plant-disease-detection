# -*- coding: utf-8 -*-
"""miniprojectplantforsem 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CwNrsDy5QDc6xBKWmJe4mIXgugE6YJmB
"""

from google.colab import drive
drive.mount('/content/drive')

dataset_path = '/content/drive/My Drive/project dataset'

import os
import cv2  # or any other image processing library
import matplotlib.pyplot as plt

image_path = os.path.join(dataset_path, '/content/f5cf6151-96d1-49bb-af1b-fa6026d749e8___RS_LB 4048_180deg.JPG')
image = cv2.imread(image_path)
plt.imshow(image)
plt.axis('off')
plt.show()

import numpy as np

import cv2
from skimage.feature import hog

def extract_sift_features(image):
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)
    return descriptors

def extract_hog_features(image):
    features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),
                              cells_per_block=(2, 2), visualize=True, multichannel=True)
    return features

!pip install opencv-python

import cv2

image = cv2.imread("/content/f5cf6151-96d1-49bb-af1b-fa6026d749e8___RS_LB 4048_180deg.JPG")

sift = cv2.SIFT_create()
keypoints, descriptors = sift.detectAndCompute(image, None)

sift_features = [descriptors]

hog = cv2.HOGDescriptor()
hog_features = [hog.compute(image)]

print("SIFT features:", sift_features)
print("HOG features:", hog_features)

import numpy as np

combined_features = np.hstack((sift_features, hog_features))

import numpy as np

print(sift_features.shape)
print(hog_features.shape)

sift_features = np.array(sift_features)
hog_features = np.array(hog_features)

print(sift_features.shape)
print(hog_features.shape)

sift_features = sift_features.reshape(-1, 1)
hog_features = hog_features.reshape(-1, 1)

combined_features = np.hstack((sift_features, hog_features))

"""Comparing number of rows

"""

if sift_features.shape[0] != hog_features.shape[0]:
    print("The arrays have different number of rows.")

if sift_features.shape[0] > hog_features.shape[0]:
    hog_features = np.resize(hog_features, (sift_features.shape[0], hog_features.shape[1]))
elif sift_features.shape[0] < hog_features.shape[0]:
    sift_features = np.resize(sift_features, (hog_features.shape[0], sift_features.shape[1]))

combined_features = np.hstack((sift_features, hog_features))

print(combined_features.shape)

sift_features = np.array(sift_features)
hog_features = np.array(hog_features)

print(sift_features.shape)
print(hog_features.shape)

combined_features = np.hstack((sift_features, hog_features))

print(combined_features.shape)

"""** SVM**"""

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#combined_features = ... # Your combined features data
#labels = ... # Your labels data

X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)

import numpy as np
from sklearn.model_selection import train_test_split

print(type(combined_features))
print(combined_features.shape)

print(type(labels))
print(labels.shape)

!pip install tensorflow

import tensorflow as tf

print(type(combined_features))

print(type(labels))

combined_features = tf.constant(combined_features)
labels = tf.constant(labels)

print(type(combined_features))
print(combined_features.shape)

print(type(labels))
print(labels.shape)

!pip install tensorflow-io

import tensorflow_io as tfio



print(type(combined_features))  # Check the type of combined_features
print(type(labels))  # Check the type of labels

!pip install pandas

import pandas as pd

print(type(combined_features))
print(type(labels))

svm_classifier = SVC(kernel='linear')

svm_classifier.fit(X_train, y_train)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

combined_features = np.array(combined_features)
labels = np.array(labels)

combined_features = np.array(combined_features)
labels = np.array(labels)

print(f"Type of combined_features: {type(combined_features)}")
print(f"Type of labels: {type(labels)}")

print("Shape of combined_features:", combined_features.shape)
print("Shape of labels:", labels.shape)
print("Data type of combined_features:", combined_features.dtype)
print("Data type of labels:", labels.dtype)

combined_features = tfio.IOTensor.from_tensor(tf.constant(combined_features))
labels = tfio.IOTensor.from_tensor(tf.constant(labels))

svm_classifier = SVC(kernel='linear')

svm_classifier.fit(1606500, 2)

import tensorflow as tf
import tensorflow_io as tfio
combined_features = tfio.IOTensor.from_tensor(tf.constant(combined_features))
labels = tfio.IOTensor.from_tensor(tf.constant(labels))

X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)

# Step 4: Create and train the SVM model
svm_model = SVC(kernel='linear', random_state=42)  # Specify the SVM parameters
svm_model.fit(X_train, y_train)

import os
import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Function to load images from the directory structure
def load_images_from_folder(folder):
    images = []
    labels = []
    for subfolder in os.listdir(folder):
        subfolder_path = os.path.join(folder, subfolder)
        if os.path.isdir(subfolder_path):
            for filename in os.listdir(subfolder_path):
                img_path = os.path.join(subfolder_path, filename)
                image = load_img(img_path, target_size=(224, 224))  # Resize images to a consistent size
                image = img_to_array(image)  # Convert image to numpy array
                images.append(image)
                labels.append(subfolder)  # Assuming folder name is the label
    return np.array(images), np.array(labels)

# Load images from train folder
train_folder = 'path/to/train/folder'
X_train, y_train = load_images_from_folder(train_folder)

# Load images from test folder
test_folder = 'path/to/test/folder'
X_test, y_test = load_images_from_folder(test_folder)

# Preprocess the images (e.g., normalize pixel values)
X_train = X_train / 255.0
X_test = X_test / 255.0

# Flatten the images or use feature extraction methods here if needed
# (e.g., using pre-trained CNN models like VGG, ResNet, etc.)

# Split the dataset into training and testing sets
# (Alternatively, you can use the provided train and test folders directly)
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the SVM model
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)

# Evaluate the model
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from google.colab import drive
drive.mount('/content/drive')

import cv2
import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Step 1: Load and preprocess your dataset
# (Assuming you have a dataset with images and corresponding labels)

# Step 2: Feature extraction using Harris Corner Detection
def extract_corners(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = np.float32(gray)
    corners = cv2.cornerHarris(gray, 2, 3, 0.04)
    # Return corner locations or feature descriptors
    return corners

# Step 3: Represent features in a suitable format
# (You may need to convert corner locations into feature vectors)

# Step 4: Split dataset into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Step 5: Train a machine learning model
# svm_model = SVC(kernel='linear')
# svm_model.fit(X_train, y_train)

# Step 6: Evaluate the model
# y_pred = svm_model.predict(X_test)
# accuracy = accuracy_score(y_test, y_pred)
# print("Accuracy:", accuracy)

plt.bar(['healthy','unhealthy'], [75,50])

plt.bar(['earlyblight','Healthy','Late Blight'], [30,85,15])





